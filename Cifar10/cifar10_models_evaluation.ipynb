{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f597a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Evaluate a given quantized model on a given quantized validation set.\n",
    "  Eventually save the accuracy of the model in the specified file.\n",
    "\n",
    "  Args:\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be evaluated.\n",
    "    valid_X: numpy.ndarray\n",
    "      The quantized validation set to be used for evaluation.\n",
    "    valid_Y: numpy.ndarray\n",
    "      The labels of the validation set.\n",
    "    model_name: str [\"AlexNet\", \"ResNet50\", \"ResNet152\", \"VGG16\"]\n",
    "      The name of the model to be evaluated.\n",
    "    quantized_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type of the model to be evaluated.\n",
    "\"\"\"\n",
    "def evaulate_quantized_model_on_quantized_ds(model: tf.lite.Interpreter, valid_X: np.ndarray, valid_Y: np.ndarray, model_name: str, quantized_type: str):\n",
    "  input_details = model.get_input_details()\n",
    "  output_details = model.get_output_details()\n",
    "\n",
    "  predictions = []\n",
    "  desc = model_name + \" \" + quantized_type + \" evaluation\"\n",
    "\n",
    "  for i in tqdm(range(len(valid_X)), desc=desc):\n",
    "    model.set_tensor(input_details[0]['index'], valid_X[i:i+1])\n",
    "    model.invoke()\n",
    "    output_data = model.get_tensor(output_details[0]['index'])\n",
    "    predictions.append(np.argmax(output_data, axis=1)[0]) \n",
    "  predictions = np.array(predictions)\n",
    "  accuracy = (np.sum(predictions == valid_Y.squeeze())/len(predictions))*100\n",
    "  \n",
    "  with open(config.MODELS_ACCURACY_PATH, 'a') as file:\n",
    "    file.write(model_name + \" \" + quantized_type + \" CIFAR-10[:\" + str(len(valid_Y)) +  \"]: \" + str(accuracy) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_alexnet():\n",
    "  model = tf.lite.Interpreter(model_path=config.ALEXNET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.ALEXNET_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'ALEXNET', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51599c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_alexnet():\n",
    "  model = tf.lite.Interpreter(model_path=config.ALEXNET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.ALEXNET_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'ALEXNET', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_resnet50():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET50_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET50', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a06069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_resnet50():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET50_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET50', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_resnet152():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET152_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET152', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_resnet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37fb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_resnet152():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET152_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET152', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_resnet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61621411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_vgg16():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.VGG16_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'VGG16', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9892be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_vgg16():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.VGG16_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'VGG16', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_mobilenet():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENET_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENET', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a68cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_mobilenet():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENET_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENET', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_mobilenetV2():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENETV2_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENETV2', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_mobilenetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_mobilenetV2():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENETV2_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENETV2', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_mobilenetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_efficientnetB0():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.EFFICIENTNETB0_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'EFFICIENTNETB0', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_efficientnetB0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_efficientnetB0():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.EFFICIENTNETB0_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'EFFICIENTNETB0', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_efficientnetB0()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
