{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels) ,\\\n",
    "(validation_images, validation_labels) = \\\n",
    "tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "  Pre-process the numpy array of images in the 'tf' mode.\n",
    "  This method scales pixels between [-1.0, 1.0], sample-wise.\n",
    "\n",
    "  Args:\n",
    "    input_images: numpy.ndarray\n",
    "      The input images to be pre-processed.\n",
    "\n",
    "  Returns:  \n",
    "    numpy.ndarray\n",
    "      The pre-processed images scaled in the [-1.0, 1.0] range.\n",
    "\"\"\"\n",
    "def pre_process_fp32_images(input_images):\n",
    "  if not isinstance(input_images, np.ndarray):\n",
    "    raise TypeError(\"dataset images expected to be of type numpy.ndarray\")\n",
    "  input_images = input_images\n",
    "  input_images = input_images.astype('float32')\n",
    "  input_images /= 127.5 # scale a pixel (8 bit -> [0.0, 255.0]) in the range [0.0, 2.0]\n",
    "  input_images -= 1.0 # adjust the range [0.0, 2.0] around 0, resulting in the range [-1.0, 1.0]\n",
    "  return input_images\n",
    "\n",
    "\"\"\"\n",
    "  Pre-process the numpy array of images in the 'tf' mode (scaling pixels between [-1.0, 1.0]) sample-wise.\n",
    "  Eventually, the pre-processed images are quantized to the specified quantization type\n",
    "  and saved in the specified path.\n",
    "\n",
    "  Args:\n",
    "    input_images: numpy.ndarray\n",
    "      The input images to be pre-processed.\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be used for retrieving quantization parameters.\n",
    "    quantization_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type to be used for quantizing the pre-processed images.\n",
    "\n",
    "  Returns:  \n",
    "    numpy.ndarray\n",
    "      The pre-processed images quantized to the specified quantization type.\n",
    "\"\"\"\n",
    "def pre_process_images_for_quantized_models(input_images, model: tf.lite.Interpreter, quantization_type: str):\n",
    "  if not isinstance(input_images, np.ndarray):\n",
    "    raise TypeError(\"dataset images expected to be of type numpy.ndarray\")\n",
    "  \n",
    "  input_details = model.get_input_details()[0]\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  \n",
    "  if quantization_type == 'int8':\n",
    "    quantized_images = tf.cast(pre_process_fp32_images(input_images) / input_scale + input_zero_point, tf.int8)\n",
    "  elif quantization_type == 'uint8':\n",
    "    quantized_images = tf.cast(pre_process_fp32_images(input_images) / input_scale + input_zero_point, tf.uint8)\n",
    "  elif quantization_type == 'int16':\n",
    "    quantized_images = pre_process_fp32_images(input_images)\n",
    "  else:\n",
    "    raise ValueError(\"quantization type not supported\")\n",
    "  \n",
    "  return quantized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in dir(config):\n",
    "  if attr.isupper():\n",
    "    value = getattr(config, attr)\n",
    "    if isinstance(value, str) and (\"/\" in value or \"\\\\\" in value):\n",
    "      dir_path = os.path.dirname(value)\n",
    "      if dir_path:\n",
    "        os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_cifar10_labels():\n",
    "  np.save(config.TRAIN_LABELS_PATH, training_labels)\n",
    "  np.save(config.VALIDATION_LABELS_PATH, validation_labels)\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 2000 CIFAR-10 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_2k_cifar10_labels():\n",
    "  np.save(config.VALIDATION_LABELS_2K_PATH, validation_labels[:2000])\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 500 CIFAR-10 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_500_cifar10_labels():\n",
    "  np.save(config.VALIDATION_LABELS_500_PATH, validation_labels[:500])\n",
    "\n",
    "\"\"\"\n",
    "  Save the CIFAR-10 preprocessed images (for fp32 models) in the specified path.\n",
    "\"\"\"\n",
    "def save_fp32_cifar10_data():\n",
    "  train_X = pre_process_fp32_images(training_images)\n",
    "  valid_X = pre_process_fp32_images(validation_images)\n",
    "  np.save(config.FP32_TRAIN_SET_PREPROCESSED_PATH, train_X)\n",
    "  np.save(config.FP32_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  \n",
    "save_cifar10_labels()\n",
    "save_fp32_cifar10_data()\n",
    "save_first_2k_cifar10_labels()\n",
    "save_first_500_cifar10_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  alexnet quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_alexnet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.ALEXNET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.ALEXNET_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.ALEXNET_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_alexnet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.ALEXNET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.ALEXNET_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.ALEXNET_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_alexnet_data()\n",
    "save_int8_cifar10_x_alexnet_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  resnet50 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_resnet50_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.RESNET50_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET50_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_resnet50_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.RESNET50_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET50_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_resnet50_data()\n",
    "save_int8_cifar10_x_resnet50_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  resnet152 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_resnet152_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.RESNET152_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET152_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_resnet152_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.RESNET152_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET152_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_resnet152_data()\n",
    "save_int8_cifar10_x_resnet152_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  vgg16 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_vgg16_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.VGG16_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.VGG16_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_vgg16_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.VGG16_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.VGG16_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_vgg16_data()\n",
    "save_int8_cifar10_x_vgg16_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  mobilenet quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_mobilenet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.MOBILENET_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENET_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_mobilenet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.MOBILENET_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENET_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_mobilenet_data()\n",
    "save_int8_cifar10_x_mobilenet_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  mobilenetV2 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_mobilenetV2_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.MOBILENETV2_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENETV2_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_mobilenetV2_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.MOBILENETV2_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENETV2_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_mobilenetV2_data()\n",
    "save_int8_cifar10_x_mobilenetV2_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  efficientnetB0 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_efficientnetB0_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.EFFICIENTNETB0_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.EFFICIENTNETB0_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_efficientnetB0_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.EFFICIENTNETB0_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.EFFICIENTNETB0_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_efficientnetB0_data()\n",
    "save_int8_cifar10_x_efficientnetB0_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
