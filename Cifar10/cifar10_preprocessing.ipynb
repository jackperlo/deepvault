{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 12:43:05.210469: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-05 12:43:05.216917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757076185.224839  106477 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757076185.227208  106477 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-05 12:43:05.235273: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(training_images, training_labels) ,\\\n",
    "(validation_images, validation_labels) = \\\n",
    "tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(validation_images[0])\n",
    "plt.title(f'{classes[validation_labels[0][0]]}')\n",
    "#plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import cv2\n",
    "\n",
    "# Carica il dataset CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Nomi delle classi CIFAR-10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def plot_enhanced_image(index=0, scale_factor=8, method='nearest'):\n",
    "    \"\"\"\n",
    "    Plotta un'immagine CIFAR-10 ingrandita per migliorare la visibilità\n",
    "    \n",
    "    Args:\n",
    "        index (int): Indice dell'immagine\n",
    "        scale_factor (int): Fattore di scala (default: 8x = 256x256)\n",
    "        method (str): Metodo di interpolazione ('nearest', 'bilinear', 'bicubic')\n",
    "    \"\"\"\n",
    "    original_image = x_test[index]\n",
    "    label = y_test[index][0]\n",
    "    \n",
    "    # Diversi metodi di scaling\n",
    "    if method == 'nearest':\n",
    "        # Nearest neighbor - mantiene pixel netti\n",
    "        scaled_image = np.repeat(np.repeat(original_image, scale_factor, axis=0), scale_factor, axis=1)\n",
    "    elif method == 'bilinear':\n",
    "        # Bilinear interpolation - più smooth\n",
    "        scaled_image = zoom(original_image, (scale_factor, scale_factor, 1), order=1)\n",
    "    elif method == 'bicubic':\n",
    "        # Bicubic interpolation - ancora più smooth\n",
    "        scaled_image = zoom(original_image, (scale_factor, scale_factor, 1), order=3)\n",
    "    \n",
    "    # Assicurati che i valori siano nel range corretto\n",
    "    scaled_image = np.clip(scaled_image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Immagine originale\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title(f'Original 32x32\\nClass: {class_names[label]}', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Immagine ingrandita\n",
    "    axes[1].imshow(scaled_image)\n",
    "    axes[1].set_title(f'Enhanced {32*scale_factor}x{32*scale_factor}\\nMethod: {method}', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Image {index}: {class_names[label]}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Original shape: {original_image.shape}\")\n",
    "    print(f\"Enhanced shape: {scaled_image.shape}\")\n",
    "\n",
    "def plot_multiple_enhancement_methods(index=0):\n",
    "    \"\"\"\n",
    "    Confronta diversi metodi di enhancement per la stessa immagine\n",
    "    \"\"\"\n",
    "    original_image = x_test[index]\n",
    "    label = y_test[index][0]\n",
    "    scale_factor = 6\n",
    "    \n",
    "    # Diversi metodi di scaling\n",
    "    nearest = np.repeat(np.repeat(original_image, scale_factor, axis=0), scale_factor, axis=1)\n",
    "    bilinear = zoom(original_image, (scale_factor, scale_factor, 1), order=1)\n",
    "    bicubic = zoom(original_image, (scale_factor, scale_factor, 1), order=3)\n",
    "    \n",
    "    # Assicura range corretto\n",
    "    nearest = np.clip(nearest, 0, 255).astype(np.uint8)\n",
    "    bilinear = np.clip(bilinear, 0, 255).astype(np.uint8)\n",
    "    bicubic = np.clip(bicubic, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    \n",
    "    # Originale\n",
    "    axes[0,0].imshow(original_image)\n",
    "    axes[0,0].set_title('Original 32x32', fontsize=12)\n",
    "    axes[0,0].axis('off')\n",
    "    \n",
    "    # Nearest neighbor\n",
    "    axes[0,1].imshow(nearest)\n",
    "    axes[0,1].set_title('Nearest Neighbor\\n(Pixel Art Style)', fontsize=12)\n",
    "    axes[0,1].axis('off')\n",
    "    \n",
    "    # Bilinear\n",
    "    axes[1,0].imshow(bilinear)\n",
    "    axes[1,0].set_title('Bilinear\\n(Smooth)', fontsize=12)\n",
    "    axes[1,0].axis('off')\n",
    "    \n",
    "    # Bicubic\n",
    "    axes[1,1].imshow(bicubic)\n",
    "    axes[1,1].set_title('Bicubic\\n(Smoother)', fontsize=12)\n",
    "    axes[1,1].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Enhancement Methods - Image {index}: {class_names[label]}', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(bicubic)\n",
    "    plt.title(f'CIFAR-10 ~ Image {index}\\nClass: {class_names[label]}', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_super_enhanced(index=0):\n",
    "    \"\"\"\n",
    "    Versione con enhancement molto grande per vedere meglio i dettagli\n",
    "    \"\"\"\n",
    "    original_image = x_test[index]\n",
    "    label = y_test[index][0]\n",
    "    \n",
    "    # Scaling molto grande (12x = 384x384)\n",
    "    scale_factor = 12\n",
    "    enhanced_image = np.repeat(np.repeat(original_image, scale_factor, axis=0), scale_factor, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(enhanced_image)\n",
    "    plt.title(f'Super Enhanced: {class_names[label]}\\n'\n",
    "              f'Size: {enhanced_image.shape[0]}x{enhanced_image.shape[1]} pixels', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Super enhanced image - Class: {class_names[label]}\")\n",
    "    print(f\"Original: {original_image.shape} -> Enhanced: {enhanced_image.shape}\")\n",
    "\n",
    "def show_enhanced_grid(start_index=0, num_images=9):\n",
    "    \"\"\"\n",
    "    Mostra una griglia di immagini enhanced\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        if start_index + i >= len(x_test):\n",
    "            break\n",
    "            \n",
    "        image = x_test[start_index + i]\n",
    "        label = y_test[start_index + i][0]\n",
    "\n",
    "        # Enhanced con nearest neighbor\n",
    "        enhanced = np.repeat(np.repeat(image, 4, axis=0), 4, axis=1)\n",
    "        \n",
    "        axes[i].imshow(enhanced)\n",
    "        axes[i].set_title(f'#{start_index + i}: {class_names[label]}', fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Enhanced CIFAR-10 Images Grid', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Esempi di utilizzo:\n",
    "\n",
    "print(\"=== Confronto Original vs Enhanced ===\")\n",
    "plot_enhanced_image(99, scale_factor=8, method='nearest')\n",
    "\n",
    "print(\"\\n=== Confronto metodi di enhancement ===\")\n",
    "plot_multiple_enhancement_methods(99)\n",
    "\n",
    "print(\"\\n=== Super enhancement ===\")\n",
    "plot_super_enhanced(99)\n",
    "\n",
    "print(\"\\n=== Griglia di immagini enhanced ===\")\n",
    "show_enhanced_grid(99, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "  Pre-process the numpy array of images in the 'tf' mode.\n",
    "  This method scales pixels between [-1.0, 1.0], sample-wise.\n",
    "\n",
    "  Args:\n",
    "    input_images: numpy.ndarray\n",
    "      The input images to be pre-processed.\n",
    "\n",
    "  Returns:  \n",
    "    numpy.ndarray\n",
    "      The pre-processed images scaled in the [-1.0, 1.0] range.\n",
    "\"\"\"\n",
    "def pre_process_fp32_images(input_images):\n",
    "  if not isinstance(input_images, np.ndarray):\n",
    "    raise TypeError(\"dataset images expected to be of type numpy.ndarray\")\n",
    "  input_images = input_images\n",
    "  input_images = input_images.astype('float32')\n",
    "  input_images /= 127.5 # scale a pixel (8 bit -> [0.0, 255.0]) in the range [0.0, 2.0]\n",
    "  input_images -= 1.0 # adjust the range [0.0, 2.0] around 0, resulting in the range [-1.0, 1.0]\n",
    "  return input_images\n",
    "\n",
    "\"\"\"\n",
    "  Pre-process the numpy array of images in the 'tf' mode (scaling pixels between [-1.0, 1.0]) sample-wise.\n",
    "  Eventually, the pre-processed images are quantized to the specified quantization type\n",
    "  and saved in the specified path.\n",
    "\n",
    "  Args:\n",
    "    input_images: numpy.ndarray\n",
    "      The input images to be pre-processed.\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be used for retrieving quantization parameters.\n",
    "    quantization_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type to be used for quantizing the pre-processed images.\n",
    "\n",
    "  Returns:  \n",
    "    numpy.ndarray\n",
    "      The pre-processed images quantized to the specified quantization type.\n",
    "\"\"\"\n",
    "def pre_process_images_for_quantized_models(input_images, model: tf.lite.Interpreter, quantization_type: str):\n",
    "  if not isinstance(input_images, np.ndarray):\n",
    "    raise TypeError(\"dataset images expected to be of type numpy.ndarray\")\n",
    "  \n",
    "  input_details = model.get_input_details()[0]\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  \n",
    "  if quantization_type == 'int8':\n",
    "    quantized_images = tf.cast(pre_process_fp32_images(input_images) / input_scale + input_zero_point, tf.int8)\n",
    "  elif quantization_type == 'uint8':\n",
    "    quantized_images = tf.cast(pre_process_fp32_images(input_images) / input_scale + input_zero_point, tf.uint8)\n",
    "  elif quantization_type == 'int16':\n",
    "    quantized_images = pre_process_fp32_images(input_images)\n",
    "  else:\n",
    "    raise ValueError(\"quantization type not supported\")\n",
    "  \n",
    "  return quantized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in dir(config):\n",
    "  if attr.isupper():\n",
    "    value = getattr(config, attr)\n",
    "    if isinstance(value, str) and (\"/\" in value or \"\\\\\" in value):\n",
    "      dir_path = os.path.dirname(value)\n",
    "      if dir_path:\n",
    "        os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_cifar10_labels():\n",
    "  np.save(config.TRAIN_LABELS_PATH, training_labels)\n",
    "  np.save(config.VALIDATION_LABELS_PATH, validation_labels)\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 2000 CIFAR-10 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_2k_cifar10_labels():\n",
    "  np.save(config.VALIDATION_LABELS_2K_PATH, validation_labels[:2000])\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 500 CIFAR-10 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_500_cifar10_labels():\n",
    "  np.save(config.VALIDATION_LABELS_500_PATH, validation_labels[:500])\n",
    "\n",
    "\"\"\"\n",
    "  Save the CIFAR-10 preprocessed images (for fp32 models) in the specified path.\n",
    "\"\"\"\n",
    "def save_fp32_cifar10_data():\n",
    "  train_X = pre_process_fp32_images(training_images)\n",
    "  valid_X = pre_process_fp32_images(validation_images)\n",
    "  np.save(config.FP32_TRAIN_SET_PREPROCESSED_PATH, train_X)\n",
    "  np.save(config.FP32_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "\n",
    "save_cifar10_labels()\n",
    "save_fp32_cifar10_data()\n",
    "save_first_2k_cifar10_labels()\n",
    "save_first_500_cifar10_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  alexnet quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_alexnet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.ALEXNET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.ALEXNET_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.ALEXNET_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_alexnet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.ALEXNET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.ALEXNET_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.ALEXNET_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_alexnet_data()\n",
    "save_int8_cifar10_x_alexnet_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  resnet18 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_resnet18_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET18_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.RESNET18_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET18_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "def save_int8_cifar10_x_resnet18_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET18_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.RESNET18_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET18_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_resnet18_data()\n",
    "save_int8_cifar10_x_resnet18_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  resnet50 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_resnet50_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.RESNET50_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET50_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_resnet50_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.RESNET50_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET50_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_resnet50_data()\n",
    "save_int8_cifar10_x_resnet50_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  resnet152 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_resnet152_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.RESNET152_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET152_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_resnet152_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.RESNET152_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET152_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_resnet152_data()\n",
    "save_int8_cifar10_x_resnet152_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  vgg16 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_vgg16_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.VGG16_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.VGG16_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_vgg16_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.VGG16_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.VGG16_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_vgg16_data()\n",
    "save_int8_cifar10_x_vgg16_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  mobilenet quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_mobilenet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.MOBILENET_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENET_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_mobilenet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.MOBILENET_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENET_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "#save_uint8_cifar10_x_mobilenet_data()\n",
    "save_int8_cifar10_x_mobilenet_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1749222193.360068  706729 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14387 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1749222193.360964  706729 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14400 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:05:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  mobilenetV2 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_mobilenetV2_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.MOBILENETV2_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENETV2_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_mobilenetV2_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.MOBILENETV2_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENETV2_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_mobilenetV2_data()\n",
    "save_int8_cifar10_x_mobilenetV2_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the CIFAR-10 pre-processed and quantized images uint8, int8 for \n",
    "  efficientnetB0 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_cifar10_x_efficientnetB0_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.EFFICIENTNETB0_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.EFFICIENTNETB0_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_cifar10_x_efficientnetB0_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.EFFICIENTNETB0_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.EFFICIENTNETB0_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_uint8_cifar10_x_efficientnetB0_data()\n",
    "save_int8_cifar10_x_efficientnetB0_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jacki_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
