{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee58f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a19b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0fbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Evaluate a given quantized model on a given quantized validation set.\n",
    "  Eventually save the accuracy of the model in the specified file.\n",
    "\n",
    "  Args:\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be evaluated.\n",
    "    valid_X: numpy.ndarray\n",
    "      The quantized validation set to be used for evaluation.\n",
    "    valid_Y: numpy.ndarray\n",
    "      The validation labels set to be used for evaluation.\n",
    "    model_name: str [\"Lenet5\"]\n",
    "      The name of the model to be evaluated.\n",
    "    quantized_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type of the model to be evaluated.\n",
    "\"\"\"\n",
    "def evaulate_quantized_model_on_quantized_ds(model: tf.lite.Interpreter, \n",
    "                                             valid_X: np.ndarray, \n",
    "                                             valid_Y: np.ndarray, \n",
    "                                             model_name: str, \n",
    "                                             quantized_type: str):\n",
    "  input_details = model.get_input_details()\n",
    "  output_details = model.get_output_details()\n",
    "\n",
    "  predictions = []\n",
    "  desc = model_name + \" \" + quantized_type + \" evaluation\"\n",
    "\n",
    "  for i in tqdm(range(len(valid_X)), desc=desc):\n",
    "    model.set_tensor(input_details[0]['index'], valid_X[i:i+1])\n",
    "    model.invoke()\n",
    "    output_data = model.get_tensor(output_details[0]['index'])\n",
    "    predictions.append(np.argmax(output_data, axis=1)[0]) \n",
    "  predictions = np.array(predictions)\n",
    "  accuracy = (np.sum(predictions == valid_Y.squeeze())/len(predictions))*100\n",
    "  \n",
    "  with open(config.MODELS_ACCURACY_PATH, 'a') as file:\n",
    "    file.write(model_name + \" \" + quantized_type + \" MNIST[:\" + str(len(valid_Y)) + \"]: \" + str(accuracy) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91bc840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lenet5 uint8 evaluation: 100%|██████████| 10000/10000 [00:00<00:00, 17286.90it/s]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_uint8_mnist_x_lenet5():\n",
    "  model = tf.lite.Interpreter(model_path=config.LENET5_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.LENET5_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X, \n",
    "                                           valid_Y, \n",
    "                                           'Lenet5', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_mnist_x_lenet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a63a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lenet5 int8 evaluation:   0%|          | 0/62 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type STRING but expected type INT8 for input 0, name: serving_default_input_layer_1:0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m   model\u001b[38;5;241m.\u001b[39mallocate_tensors()\n\u001b[1;32m      4\u001b[0m   evaulate_quantized_model_on_quantized_ds(model, \n\u001b[1;32m      5\u001b[0m                                            config\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      6\u001b[0m                                             LENET5_I8_VALIDATION_SET_PREPROCESSED_PATH, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLenet5\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     10\u001b[0m                                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m evaluate_int8_mnist_x_lenet5()\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mevaluate_int8_mnist_x_lenet5\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter(model_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mLENET5_I8_MODEL_PATH)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mallocate_tensors()\n\u001b[0;32m----> 4\u001b[0m evaulate_quantized_model_on_quantized_ds(model, \n\u001b[1;32m      5\u001b[0m                                          config\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      6\u001b[0m                                           LENET5_I8_VALIDATION_SET_PREPROCESSED_PATH, \n\u001b[1;32m      7\u001b[0m                                          config\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      8\u001b[0m                                           VALIDATION_LABELS_PATH, \n\u001b[1;32m      9\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLenet5\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     10\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mevaulate_quantized_model_on_quantized_ds\u001b[0;34m(model, valid_X, valid_Y, model_name, quantized_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m desc \u001b[38;5;241m=\u001b[39m model_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m quantized_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(valid_X)), desc\u001b[38;5;241m=\u001b[39mdesc):\n\u001b[0;32m---> 29\u001b[0m   model\u001b[38;5;241m.\u001b[39mset_tensor(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], valid_X[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     30\u001b[0m   model\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[1;32m     31\u001b[0m   output_data \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_tensor(output_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:720\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    705\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter\u001b[38;5;241m.\u001b[39mSetTensor(tensor_index, value)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got value of type STRING but expected type INT8 for input 0, name: serving_default_input_layer_1:0 "
     ]
    }
   ],
   "source": [
    "def evaluate_int8_mnist_x_lenet5():\n",
    "  model = tf.lite.Interpreter(model_path=config.LENET5_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.LENET5_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X, \n",
    "                                           valid_Y, \n",
    "                                           'Lenet5', \n",
    "                                           'int8')\n",
    "\n",
    "evaluate_int8_mnist_x_lenet5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
