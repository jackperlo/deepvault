{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee58f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a19b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0fbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Evaluate a given quantized model on a given quantized validation set.\n",
    "  Eventually save the accuracy of the model in the specified file.\n",
    "\n",
    "  Args:\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be evaluated.\n",
    "    valid_X: numpy.ndarray\n",
    "      The quantized validation set to be used for evaluation.\n",
    "    valid_Y: numpy.ndarray\n",
    "      The validation labels set to be used for evaluation.\n",
    "    model_name: str [\"Lenet5\"]\n",
    "      The name of the model to be evaluated.\n",
    "    quantized_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type of the model to be evaluated.\n",
    "\"\"\"\n",
    "def evaulate_quantized_model_on_quantized_ds(model: tf.lite.Interpreter, \n",
    "                                             valid_X: np.ndarray, \n",
    "                                             valid_Y: np.ndarray, \n",
    "                                             model_name: str, \n",
    "                                             quantized_type: str):\n",
    "  input_details = model.get_input_details()\n",
    "  output_details = model.get_output_details()\n",
    "\n",
    "  predictions = []\n",
    "  desc = model_name + \" \" + quantized_type + \" evaluation\"\n",
    "\n",
    "  for i in tqdm(range(len(valid_X)), desc=desc):\n",
    "    model.set_tensor(input_details[0]['index'], valid_X[i:i+1])\n",
    "    model.invoke()\n",
    "    output_data = model.get_tensor(output_details[0]['index'])\n",
    "    predictions.append(np.argmax(output_data, axis=1)[0]) \n",
    "  predictions = np.array(predictions)\n",
    "  accuracy = (np.sum(predictions == valid_Y.squeeze())/len(predictions))*100\n",
    "  \n",
    "  with open(config.MODELS_ACCURACY_PATH, 'a') as file:\n",
    "    file.write(model_name + \" \" + quantized_type + \" MNIST[:\" + str(len(valid_Y)) + \"]: \" + str(accuracy) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91bc840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lenet5 uint8 evaluation: 100%|██████████| 10000/10000 [00:00<00:00, 17286.90it/s]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_uint8_mnist_x_lenet5():\n",
    "  model = tf.lite.Interpreter(model_path=config.LENET5_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.LENET5_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X, \n",
    "                                           valid_Y, \n",
    "                                           'Lenet5', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_mnist_x_lenet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a63a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lenet5 int8 evaluation: 100%|██████████| 10000/10000 [00:00<00:00, 16480.05it/s]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_int8_mnist_x_lenet5():\n",
    "  model = tf.lite.Interpreter(model_path=config.LENET5_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.LENET5_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X, \n",
    "                                           valid_Y, \n",
    "                                           'Lenet5', \n",
    "                                           'int8')\n",
    "\n",
    "evaluate_int8_mnist_x_lenet5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
