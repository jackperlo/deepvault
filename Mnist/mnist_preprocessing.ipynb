{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), \\\n",
    "(validation_images, validation_labels) = \\\n",
    "  tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Pre-process the numpy array of images.\n",
    "  This method scales pixels between [0.0, 1.0], sample-wise.\n",
    "\n",
    "  Args:\n",
    "    input_images: numpy.ndarray\n",
    "      The input images to be pre-processed.\n",
    "\n",
    "  Returns:  \n",
    "    numpy.ndarray\n",
    "      The pre-processed images scaled in the [0.0, 1.0] range.\n",
    "\"\"\"\n",
    "def pre_process_fp32_images(input_images):\n",
    "  if not isinstance(input_images, np.ndarray):\n",
    "    raise TypeError(\"dataset images expected to be of type numpy.ndarray\")\n",
    "  \n",
    "  preprocessed_images = tf.pad(input_images, [[0, 0], [2, 2], [2, 2]]) / 255\n",
    "  preprocessed_images = tf.expand_dims(preprocessed_images, axis=3, name=None)\n",
    "  return preprocessed_images\n",
    "\n",
    "\"\"\"\n",
    "  Pre-process the numpy array of images (scaling pixels between [0.0, 1.0]) sample-wise.\n",
    "  Eventually, the pre-processed images are quantized to the specified quantization type\n",
    "  and saved in the specified path.\n",
    "\n",
    "  Args:\n",
    "    input_images: numpy.ndarray\n",
    "      The input images to be pre-processed.\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be used for retrieving quantization parameters.\n",
    "    quantization_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type to be used for quantizing the pre-processed images.\n",
    "\n",
    "  Returns:  \n",
    "    numpy.ndarray\n",
    "      The pre-processed images quantized to the specified quantization type.\n",
    "\"\"\"\n",
    "def pre_process_images_for_quantized_models(input_images, \n",
    "                                            model: tf.lite.Interpreter, \n",
    "                                            quantization_type: str):\n",
    "  if not isinstance(input_images, np.ndarray):\n",
    "    raise TypeError(\"dataset images expected to be of type numpy.ndarray\")\n",
    "  \n",
    "  input_details = model.get_input_details()[0]\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  \n",
    "  if quantization_type == 'int8':\n",
    "    quantized_images = tf.cast(pre_process_fp32_images(input_images) / input_scale + input_zero_point, tf.int8)\n",
    "  elif quantization_type == 'uint8':\n",
    "    quantized_images = tf.cast(pre_process_fp32_images(input_images) / input_scale + input_zero_point, tf.uint8)\n",
    "  elif quantization_type == 'int16':\n",
    "    quantized_images = pre_process_fp32_images(input_images)\n",
    "  else:\n",
    "    raise ValueError(\"quantization type not supported\")\n",
    "  \n",
    "  return quantized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in dir(config):\n",
    "  if attr.isupper():\n",
    "    value = getattr(config, attr)\n",
    "    if isinstance(value, str) and (\"/\" in value or \"\\\\\" in value):\n",
    "      dir_path = os.path.dirname(value)\n",
    "      if dir_path:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  Save the MNIST labels in the specified path.\n",
    "\"\"\"\n",
    "def save_mnist_labels():\n",
    "  np.save(config.TRAIN_LABELS_PATH, training_labels)\n",
    "  np.save(config.VALIDATION_LABELS_PATH, validation_labels)\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 2000 MNIST labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_2k_mnist_labels():\n",
    "  np.save(config.VALIDATION_LABELS_2K_PATH, validation_labels[:2000])\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 500 MNIST labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_500_mnist_labels():\n",
    "  np.save(config.VALIDATION_LABELS_500_PATH, validation_labels[:500])\n",
    "\n",
    "\"\"\"\n",
    "  Save the MNIST preprocessed images (for any fp32 models) in the specified path.\n",
    "\"\"\"\n",
    "def save_fp32_mnist_data():\n",
    "  train_X = pre_process_fp32_images(training_images)\n",
    "  valid_X = pre_process_fp32_images(validation_images)\n",
    "  np.save(config.FP32_TRAIN_SET_PREPROCESSED_PATH, train_X)\n",
    "  np.save(config.FP32_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "\n",
    "\"\"\"\n",
    "  Save the MNIST uint8 preprocessed images for lenet5 model in the specified path.\n",
    "\"\"\"\n",
    "def save_uint8_mnist_x_lenet5_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.LENET5_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'uint8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.LENET5_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.LENET5_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "\"\"\"\n",
    "  Save the MNIST int8 preprocessed images for lenet5 model in the specified path.\n",
    "\"\"\"\n",
    "def save_int8_mnist_x_lenet5_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.LENET5_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  _train_X = pre_process_images_for_quantized_models(training_images, model, 'int8')\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.LENET5_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.LENET5_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "save_fp32_mnist_data()\n",
    "save_mnist_labels()\n",
    "save_first_500_mnist_labels()\n",
    "save_first_2k_mnist_labels()\n",
    "save_uint8_mnist_x_lenet5_data()\n",
    "save_int8_mnist_x_lenet5_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
