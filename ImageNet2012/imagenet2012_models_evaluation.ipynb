{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169f6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09133dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b0c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Evaluate a given quantized model on a given quantized validation set.\n",
    "  Eventually save the accuracy of the model in the specified file.\n",
    "\n",
    "  Args:\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be evaluated.\n",
    "    valid_X: numpy.ndarray\n",
    "      The quantized validation set to be used for evaluation.\n",
    "    valid_Y: numpy.ndarray\n",
    "      The labels of the validation set.\n",
    "    model_name: str [\"AlexNet\", \"ResNet50\", \"ResNet152\", \"VGG16\"]\n",
    "      The name of the model to be evaluated.\n",
    "    quantized_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type of the model to be evaluated.\n",
    "\"\"\"\n",
    "def evaulate_quantized_model_on_quantized_ds(model: tf.lite.Interpreter, \n",
    "                                             valid_X: np.ndarray, \n",
    "                                             valid_Y: np.ndarray, \n",
    "                                             model_name: str, \n",
    "                                             quantized_type: str):\n",
    "  input_details = model.get_input_details()\n",
    "  output_details = model.get_output_details()\n",
    "\n",
    "  predictions = []\n",
    "  desc = model_name + \" \" + quantized_type + \" evaluation\"\n",
    "\n",
    "  for i in tqdm(range(len(valid_X)), desc=desc):\n",
    "    model.set_tensor(input_details[0]['index'], valid_X[i:i+1])\n",
    "    model.invoke()\n",
    "    output_data = model.get_tensor(output_details[0]['index'])\n",
    "    predictions.append(np.argmax(output_data, axis=1)[0]) \n",
    "  predictions = np.array(predictions)\n",
    "  accuracy = (np.sum(predictions == valid_Y.squeeze())/len(predictions))*100\n",
    "  \n",
    "  with open(config.MODELS_ACCURACY_PATH, 'a') as file:\n",
    "    file.write(model_name + \" \" + quantized_type + \" IMAGENET2012 [:\" + str(len(valid_Y)) +  \"]: \" + str(accuracy) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba696f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_resnet50():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET50_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET50', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ceb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_resnet50():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET50_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET50', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_resnet152():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET152_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET152', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_resnet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57034dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_resnet152():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.RESNET152_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'RESNET152', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_resnet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d4440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_vgg16():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.VGG16_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'VGG16', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_vgg16():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.VGG16_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'VGG16', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_mobilenetV1():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENET_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENET', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_mobilenetV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0825823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_mobilenetV1():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENET_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENET', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_mobilenetV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f092f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_mobilenetV2():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENETV2_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENETV2', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_mobilenetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec241c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_mobilenetV2():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.MOBILENETV2_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'MOBILENETV2', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_mobilenetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52971b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uint8_imagenet2012_x_efficientnetB0():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.EFFICIENTNETB0_U8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'EFFICIENTNETB0', \n",
    "                                           'uint8')\n",
    "  \n",
    "evaluate_uint8_imagenet2012_x_efficientnetB0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9afb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_int8_imagenet2012_x_efficientnetB0():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = np.load(config.EFFICIENTNETB0_I8_VALIDATION_SET_PREPROCESSED_PATH+\".npy\")\n",
    "  valid_Y = np.load(config.VALIDATION_LABELS_PATH)\n",
    "  evaulate_quantized_model_on_quantized_ds(model, \n",
    "                                           valid_X[config.N_IMAGES_SLICE], \n",
    "                                           valid_Y[config.N_IMAGES_SLICE],\n",
    "                                           'EFFICIENTNETB0', \n",
    "                                           'int8')\n",
    "  \n",
    "evaluate_int8_imagenet2012_x_efficientnetB0()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
