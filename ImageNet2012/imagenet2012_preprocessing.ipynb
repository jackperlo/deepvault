{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from imagenet2012_utils import ImageNetDataset\n",
    "import config\n",
    "from huggingface_hub import hf_hub_download\n",
    "import shutil\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš§ Downloading 50k compressed validation images from Imagenet2012 dataset from Hugging Face Hub into ./datasets_data/imagenet2012_compressed ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210a1d2984e34dde9528555013020ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ILSVRC2012.tar.gz:   0%|          | 0.00/6.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 50k compressed validation images from ImageNet2012 saved to: ./datasets_data/imagenet2012_compressed/ILSVRC2012.tar.gz\n",
      "\n",
      "ðŸš§ Starting decompression from ./datasets_data/imagenet2012_compressed/ILSVRC2012.tar.gz into ./datasets_data/imagenet2012/ \n",
      "âœ… Decompression complete. Extracted images and labels saved in: ./datasets_data/imagenet2012/\n"
     ]
    }
   ],
   "source": [
    "# download ImageNet-2012 dataset\n",
    "\n",
    "repo_id = \"jack-perlo/ILSVRC-2012\"\n",
    "filename = \"ILSVRC2012.tar.gz\"\n",
    "local_dir = \"./datasets_data/imagenet2012_compressed\"\n",
    "images_tar_path = './datasets_data/imagenet2012_compressed/ILSVRC2012.tar.gz'\n",
    "imgs_extract_dir = './datasets_data/' # 50k validation images and respective labels\n",
    "\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "os.makedirs(imgs_extract_dir, exist_ok=True)\n",
    "\n",
    "if os.listdir(local_dir):\n",
    "  print(f\"âœ… {local_dir} already contains data. Skipping download and extraction.\")\n",
    "else: \n",
    "  print(f\"ðŸš§ Downloading 50k compressed validation images from Imagenet2012 dataset from Hugging Face Hub into {local_dir} ...\")\n",
    "  # Download the model file\n",
    "  local_path = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\")\n",
    "  # Copy to the target directory\n",
    "  shutil.copy(local_path, os.path.join(local_dir, filename))\n",
    "  print(f\"âœ… 50k compressed validation images from ImageNet2012 saved to: {local_dir}/{filename}\")\n",
    "\n",
    "  print(f\"\\nðŸš§ Starting decompression from {local_dir}/{filename} into {imgs_extract_dir} \")\n",
    "  with tarfile.open(images_tar_path, 'r:gz') as imgs_tar:\n",
    "    imgs_tar.extractall(path=imgs_extract_dir)\n",
    "  print(f\"âœ… Decompression complete. Extracted images and labels saved in: {imgs_extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Get the numpy array of images for the quantized models.\n",
    "  Eventually, the images are quantized to the specified quantization type\n",
    "  and saved in the specified path.\n",
    "\n",
    "  Args:\n",
    "    input_images: numpy.ndarray\n",
    "      The float32 input images to be processed.\n",
    "    model: tf.lite.Interpreter\n",
    "      The model to be used for retrieving quantization parameters.\n",
    "    quantization_type: str [\"int8\", \"uint8\", \"int16\"]\n",
    "      The quantization type to be used for quantizing the processed images.\n",
    "\n",
    "  Returns:  \n",
    "    numpy.ndarray\n",
    "      The images quantized to the specified quantization type.\n",
    "\"\"\"\n",
    "def pre_process_images_for_quantized_models(input_images, \n",
    "                                            model: tf.lite.Interpreter, \n",
    "                                            quantization_type: str):\n",
    "  if not isinstance(input_images, np.ndarray):\n",
    "    raise TypeError(\"dataset images expected to be of type numpy.ndarray\")\n",
    "  \n",
    "  input_details = model.get_input_details()[0]\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  \n",
    "  if quantization_type == 'int8':\n",
    "    quantized_images = tf.cast(input_images/ input_scale + input_zero_point, tf.int8)\n",
    "  elif quantization_type == 'uint8':\n",
    "    quantized_images = tf.cast(input_images/ input_scale + input_zero_point, tf.uint8)\n",
    "  elif quantization_type == 'int16' or quantization_type == 'fp32':\n",
    "    return input_images\n",
    "  else:\n",
    "    raise ValueError(\"quantization type not supported\")\n",
    "  \n",
    "  return quantized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in dir(config):\n",
    "  if attr.isupper():\n",
    "    value = getattr(config, attr)\n",
    "    if isinstance(value, str) and (\"/\" in value or \"\\\\\" in value):\n",
    "      dir_path = os.path.dirname(value)\n",
    "      if dir_path:\n",
    "        os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the IMAGENET2012 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_imagenet2012_labels():\n",
    "  np.save(config.VALIDATION_LABELS_PATH, validation_labels)\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 2000 IMAGENET2012 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_2k_imagenet2012_labels():\n",
    "  np.save(config.VALIDATION_LABELS_2K_PATH, validation_labels[:2000])\n",
    "\n",
    "\"\"\"\n",
    "  Save the first 500 IMAGENET2012 labels in the specified path.\n",
    "\"\"\"\n",
    "def save_first_500_imagenet2012_labels():\n",
    "  np.save(config.VALIDATION_LABELS_500_PATH, validation_labels[:500])\n",
    "\n",
    "\n",
    "(_, _) ,\\\n",
    "(_, validation_labels) = \\\n",
    "ImageNetDataset.load_validation_dataset(mode='only_labels')\n",
    "\n",
    "save_imagenet2012_labels()\n",
    "save_first_2k_imagenet2012_labels()\n",
    "save_first_500_imagenet2012_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Save the Imagenet2012 pre-processed and quantized images uint8, int8 for\n",
    "  ResNet50 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_imagenet2012_x_resnet50_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.RESNET50_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET50_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_imagenet2012_x_resnet50_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET50_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.RESNET50_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET50_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "(training_images, training_labels) ,\\\n",
    "(validation_images, validation_labels) = \\\n",
    "ImageNetDataset.load_validation_dataset(mode='resnet50')\n",
    "\n",
    "save_uint8_imagenet2012_x_resnet50_data()\n",
    "save_int8_imagenet2012_x_resnet50_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738592138.501825 3116630 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14408 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "RESNET152 uint8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [07:25<00:00, 22.45it/s]\n",
      "RESNET152 uint8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [01:29<00:00, 22.43it/s]\n",
      "RESNET152 uint8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:22<00:00, 22.45it/s]\n",
      "RESNET152 int8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [07:24<00:00, 22.50it/s]\n",
      "RESNET152 int8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [01:28<00:00, 22.51it/s]\n",
      "RESNET152 int8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:22<00:00, 22.48it/s]\n",
      "RESNET152 int16 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [15:37<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  Save the Imagenet2012 pre-processed and quantized images uint8, int8 for\n",
    "  ResNet152 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_imagenet2012_x_resnet152_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.RESNET152_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET152_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_imagenet2012_x_resnet152_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.RESNET152_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.RESNET152_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.RESNET152_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "(training_images, training_labels) ,\\\n",
    "(validation_images, validation_labels) = \\\n",
    "ImageNetDataset.load_validation_dataset(mode='resnet152')\n",
    "\n",
    "save_uint8_imagenet2012_x_resnet152_data()\n",
    "save_int8_imagenet2012_x_resnet152_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VGG16 int16 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [21:04<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "  Save the Imagenet2012 pre-processed and quantized images uint8, int8 for\n",
    "  VGG16 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "\n",
    "def save_uint8_imagenet2012_x_vgg16_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.VGG16_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.VGG16_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "def save_int8_imagenet2012_x_vgg16_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.VGG16_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.VGG16_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.VGG16_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "\n",
    "(training_images, training_labels) ,\\\n",
    "(validation_images, validation_labels) = \\\n",
    "ImageNetDataset.load_validation_dataset(mode='vgg16')\n",
    "\n",
    "save_uint8_imagenet2012_x_vgg16_data()\n",
    "save_int8_imagenet2012_x_vgg16_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 13:46:02.839176: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 6021160192 bytes after encountering the first element of size 6021160192 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "MOBILENET uint8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:07<00:00, 63.75it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "  Save the imagenet2012 pre-processed and quantized images uint8, int8 for\n",
    "  MobileNetV1 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "def save_uint8_imagenet2012_x_mobilenet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.MOBILENET_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENET_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    " \n",
    "def save_int8_imagenet2012_x_mobilenet_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENET_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.MOBILENET_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENET_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "(training_images, training_labels) ,\\\n",
    "(validation_images, validation_labels) = \\\n",
    "ImageNetDataset.load_validation_dataset(mode='mobilenet')\n",
    "\n",
    "save_uint8_imagenet2012_x_mobilenet_data()\n",
    "save_int8_imagenet2012_x_mobilenet_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738335752.090661 3085311 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14308 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:05:00.0, compute capability: 8.6\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "MOBILENETV2 uint8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:30<00:00, 329.59it/s]\n",
      "MOBILENETV2 uint8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:06<00:00, 330.46it/s]\n",
      "MOBILENETV2 int8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:29<00:00, 343.11it/s]\n",
      "MOBILENETV2 int8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:05<00:00, 345.42it/s]\n",
      "MOBILENETV2 int16 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [02:57<00:00, 11.25it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  Save the imagenet2012 pre-processed and quantized images uint8, int8 for\n",
    "  MobilenetV2 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "def save_uint8_imagenet2012_x_mobilenetV2_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.MOBILENETV2_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENETV2_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_imagenet2012_x_mobilenetV2_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.MOBILENETV2_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.MOBILENETV2_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.MOBILENETV2_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "  \n",
    "(training_images, training_labels) ,\\\n",
    "(validation_images, validation_labels) = \\\n",
    "ImageNetDataset.load_validation_dataset(mode='mobilenetv2')\n",
    "\n",
    "save_uint8_imagenet2012_x_mobilenetV2_data()\n",
    "save_int8_imagenet2012_x_mobilenetV2_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738751859.385158 3185753 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14370 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:05:00.0, compute capability: 8.6\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "EFFICIENTNETB0 uint8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:10<00:00, 46.67it/s]\n",
      "EFFICIENTNETB0 int8 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:08<00:00, 58.03it/s]\n",
      "EFFICIENTNETB0 int16 evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [02:13<00:00,  3.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  Save the imagenet2012 pre-processed and quantized images uint8, int8 for\n",
    "  EfficientnetB0 quantized models, in the specified paths.\n",
    "\"\"\"\n",
    "def save_uint8_imagenet2012_x_efficientnetB0_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_U8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'uint8')\n",
    "  np.save(config.EFFICIENTNETB0_U8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.EFFICIENTNETB0_U8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "def save_int8_imagenet2012_x_efficientnetB0_data():\n",
    "  model = tf.lite.Interpreter(model_path=config.EFFICIENTNETB0_I8_MODEL_PATH)\n",
    "  model.allocate_tensors()\n",
    "  valid_X = pre_process_images_for_quantized_models(validation_images, model, 'int8')\n",
    "  np.save(config.EFFICIENTNETB0_I8_VALIDATION_SET_PREPROCESSED_PATH, valid_X)\n",
    "  np.save(config.EFFICIENTNETB0_I8_2K_VALIDATION_SET_PREPROCESSED_PATH, valid_X[:2000])\n",
    "  \n",
    "(training_images, training_labels) , \\\n",
    "(validation_images, validation_labels) = \\\n",
    "ImageNetDataset.load_validation_dataset(mode='efficientnetb0')\n",
    "\n",
    "save_uint8_imagenet2012_x_efficientnetB0_data()\n",
    "save_int8_imagenet2012_x_efficientnetB0_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
